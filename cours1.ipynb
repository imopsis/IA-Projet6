{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Charger l'image\n",
    "img = Image.open(\"C:/Users/david/Dropbox/Openclassrooms/IA/Projet 6/intemporellement-votre.jpg\") \n",
    "img = Image.open(\"C:/Users/david/Dropbox/Openclassrooms/IA/Projet 6/15180252235774_simba.png\") \n",
    "\n",
    "\n",
    "# Afficher l'image chargée\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largeur : 250 px, hauteur : 263 px\n"
     ]
    }
   ],
   "source": [
    "# Récupérer et afficher la taille de l'image (en pixels)\n",
    "w, h = img.size\n",
    "print(\"Largeur : {} px, hauteur : {} px\".format(w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format des pixels : L\n",
      "Valeur du pixel situé en (20,100) : 196\n"
     ]
    }
   ],
   "source": [
    "# Afficher son mode de quantification\n",
    "print(\"Format des pixels : {}\".format(img.mode))\n",
    "\n",
    "# Récupérer et afficher la valeur du pixel à une position précise\n",
    "px_value = img.getpixel((20,100))\n",
    "print(\"Valeur du pixel situé en (20,100) : {}\".format(px_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[247 245 245 ... 224 228 228]\n",
      " [246 244 243 ... 228 230 230]\n",
      " [244 242 240 ... 230 231 231]\n",
      " ...\n",
      " [183 169 169 ... 108  95 102]\n",
      " [170 160 171 ...  81  95  99]\n",
      " [150 155 174 ... 133 115 111]]\n",
      "Taille de la matrice de pixels : (263, 250)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Récupérer les valeurs de tous les pixels sous forme d'une matrice\n",
    "mat = np.array(img)\n",
    "print(mat)\n",
    "\n",
    "# Afficher la taille de la matrice de pixels\n",
    "print(\"Taille de la matrice de pixels : {}\".format(mat.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Charger l'image comme matrice de pixels\n",
    "img = np.array(Image.open(\"C:/Users/david/Dropbox/Openclassrooms/IA/Projet 6/intemporellement-votre.jpg\"))\n",
    "img = np.array(Image.open(\"C:/Users/david/Dropbox/Openclassrooms/IA/Projet 6/15180252235774_simba.png\"))\n",
    "\n",
    "# Générer et afficher l'histogramme\n",
    "# Pour le normaliser : argument density=True dans plt.hist\n",
    "# Pour avoir l'histogramme cumulé : argument cumulative=True\n",
    "n, bins, patches = plt.hist(img.flatten(), bins=range(256))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Dimensions du tableau (shape) : (263, 250)\n",
      "Type de données du tableau (dtype) : uint8\n"
     ]
    }
   ],
   "source": [
    "# Générer le bruit gaussien de moyenne nulle et d'écart-type 7 (variance 49)\n",
    "noise = np.random.normal(0, 7, img.shape)\n",
    "\n",
    "print(type(img))\n",
    "\n",
    "print(\"Dimensions du tableau (shape) :\", img.shape)\n",
    "print(\"Type de données du tableau (dtype) :\", img.dtype)\n",
    "\n",
    "# Créer l'image bruitée et l'afficher\n",
    "noisy_img = Image.fromarray(img + noise).convert('L')\n",
    "noisy_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFilter\n",
    "\n",
    "# Appliquer le lissage par moyennage (fenêtre de taille 9) et afficher le résultat\n",
    "noisy_img.filter(ImageFilter.BoxBlur(1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "my_VGG16 = Sequential()  # Création d'un réseau de neurones vide "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Ajout de la première couche de convolution, suivie d'une couche ReLU\n",
    "my_VGG16.add(Conv2D(64, (3, 3), input_shape=(224, 224, 3), padding='same', activation='relu'))\n",
    "\n",
    "# Ajout de la deuxième couche de convolution, suivie  d'une couche ReLU\n",
    "my_VGG16.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "\n",
    "# Ajout de la première couche de pooling\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "my_VGG16.add(Flatten())  # Conversion des matrices 3D en vecteur 1D\n",
    "\n",
    "# Ajout de la première couche fully-connected, suivie d'une couche ReLU\n",
    "my_VGG16.add(Dense(4096, activation='relu'))\n",
    "\n",
    "# Ajout de la deuxième couche fully-connected, suivie d'une couche ReLU\n",
    "my_VGG16.add(Dense(4096, activation='relu'))\n",
    "\n",
    "# Ajout de la dernière couche fully-connected qui permet de classifier\n",
    "my_VGG16.add(Dense(1000, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "model = VGG16() # Création du modèle VGG-16 implementé par Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n",
      "3.3.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(\"C:/Users/david/Dropbox/Openclassrooms/IA/Projet 6/chat-roux.jpeg\", target_size=(224, 224))  # Charger l'image\n",
    "img = img_to_array(img)  # Convertir en tableau numpy\n",
    "img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))  # Créer la collection d'images (un seul échantillon)\n",
    "img = preprocess_input(img)  # Prétraiter l'image comme le veut VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n"
     ]
    }
   ],
   "source": [
    "y = model.predict(img)  # Prédir la classe de l'image (parmi les 1000 classes d'ImageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Top 3 : [('n02123159', 'tiger_cat', 0.4742974), ('n02124075', 'Egyptian_cat', 0.31934333), ('n02123045', 'tabby', 0.10532761)]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import decode_predictions\n",
    "\n",
    "# Afficher les 3 classes les plus probables\n",
    "print('Top 3 :', decode_predictions(y, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la section précédente, nous avons utilisé le réseau VGG-16 fourni par Keras pour résoudre le même problème de classification que celui sur lequel il a été pré-entraîné (classification à 1000 classes avec ImageNet). En pratique, vous serez très probablement confrontés à un nouveau problème de classification. Dans ce cas, savoir mettre en oeuvre le Transfer Learning vous sera très utile ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je vous encourage tout d'abord à bien vous remettre en tête les stratégies possibles, introduites dans le chapitre précédent : fine-tuning total, extraction des features, et fine-tuning partiel. \n",
    "\n",
    "Dans les trois cas, il faut remplacer les dernières couches fully-connected qui permettent de classifier l'image dans une des 1000 classes ImageNet) par un classifieur plus adapté à notre problème.  Par exemple, supposons qu'on veuille différencier un chat d'un chien (classification binaire). La suppression des dernières couches se fait en ajoutant l'argument  include_top = False  lors de l'import du modèle pré-entraîné. Dans ce cas, il faut aussi préciser les dimensions des images en entrée (input_shape ) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense\n",
    "from keras import Model\n",
    "# Charger VGG-16 pré-entraîné sur ImageNet et sans les couches fully-connected\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Récupérer la sortie de ce réseau\n",
    "x = model.output\n",
    "\n",
    "# Ajouter la nouvelle couche fully-connected pour la classification à 10 classes\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Définir le nouveau modèle\n",
    "new_model = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratégie #1 : fine-tuning total\n",
    "\n",
    "La stratégie #1 doit être utilisée lorsque la nouvelle collection d'images est grande : dans ce cas, on peut se permettre d'entraîner tout le réseau sans courir le risque d'overfitting. De plus, comme les paramètres de toutes les couches (sauf de la dernière) sont initialement ceux du réseau pré-entraîné, la phase d'apprentissage sera faite plus rapidement que si l'initialisation avait été aléatoire.\n",
    "\n",
    "Ici, on entraîne tout le réseau, donc il faut rendre toutes les couches \"entraînables\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratégie #2 : extraction de features\n",
    "\n",
    "La stratégie #2 doit être utilisée lorsque la nouvelle collection d'images est petite et similaire aux images de pré-entraînement. En effet, entraîner le réseau sur aussi peu d'images est dangereux puisque le risque d'overfitting est important. De plus, si les nouvelles images ressemblent aux anciennes, elles peuvent alors être représentées par les mêmes features.\n",
    "\n",
    "On entraîne seulement le nouveau classifieur et on ne ré-entraîne pas les autres couches :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "   layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratégie #3 : fine-tuning partiel\n",
    "\n",
    "On utilise cette stratégie lorsque la nouvelle collection d'images est petite mais très différente des images du pré-entraînement. D'une part, comme il y a peu d'images d'entraînement, la stratégie #1 qui consiste à entraîner tout le réseau n'est pas envisageable à cause du risque d'overfitting.\n",
    "\n",
    "D'autre part, on élimine également la stratégie #2 puisque les nouvelles images ont très peu de points communs avec les anciennes : utiliser les features du réseau pré-entraîné pour les représenter n'est pas une bonne idée ! Mais souvenez-vous : les features des couches basses sont simples et génériques (donc peuvent se retrouver dans deux images très différentes), tandis que celles des couches hautes sont complexes et spécifiques au problème. Ainsi, la stratégie de fixer les couches basses et d'entraîner le classifieur et les couches hautes constitue un bon compromis.\n",
    "\n",
    "On entraîne le nouveau classifieur et les couches hautes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ne pas entraîner les 5 premières couches (les plus basses) \n",
    "for layer in model.layers[:5]:\n",
    "   layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement du réseau\n",
    "Il ne reste plus qu'à compiler le nouveau modèle, puis à l'entraîner  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le modèle \n",
    "new_model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraîner sur les données d'entraînement (X_train, y_train)\n",
    "model_info = new_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
